{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab05203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Patient Post\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"output.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "posts = df['translated_post'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7d9c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 105 DSM-5 criteria\n",
      "Example criterion: Severe recurrent temper outbursts manifested verbally (e.g., verbal rages) and/or be-\n",
      "haviorally (e....\n",
      "=== CLEANING DATA ===\n",
      "Cleaned data: 105 -> 105 items\n",
      "All items are strings: True\n",
      "No empty strings: True\n",
      "Sample: Severe recurrent temper outbursts manifested verba...\n"
     ]
    }
   ],
   "source": [
    "#Load DSM-5 Criteria from json file\n",
    "\n",
    "import json\n",
    "from typing import List, Dict, Iterable, Tuple, Any\n",
    "\n",
    "dsm_path = \"DSM-5/DSM_Criteria_Array_Fixed.json\"\n",
    "\n",
    "with open(dsm_path, 'r', encoding='utf-8') as f:\n",
    "    dsm_data = json.load(f)\n",
    "\n",
    "criteria_texts: List[str] = []\n",
    "criteria_details: List[Dict[str, str]] = []\n",
    "\n",
    "for item in dsm_data:\n",
    "    diagnosis = item.get(\"diagnosis\", \"\")\n",
    "    criteria_list = item.get(\"criteria\", [])\n",
    "    \n",
    "    # Each criterion is a dict with \"id\" and \"text\" keys\n",
    "    for criterion_dict in criteria_list:\n",
    "        criterion_text = criterion_dict.get(\"text\", \"\").strip()\n",
    "        criterion_id = criterion_dict.get(\"id\", \"\")\n",
    "        \n",
    "        if criterion_text:  # Only add non-empty criteria\n",
    "            criteria_texts.append(criterion_text)\n",
    "            criteria_details.append({\n",
    "                \"diagnosis\": diagnosis,\n",
    "                \"criterion_id\": criterion_id,\n",
    "                \"text\": criterion_text\n",
    "            })\n",
    "\n",
    "print(f\"Loaded {len(criteria_texts)} DSM-5 criteria\")\n",
    "print(f\"Example criterion: {criteria_texts[0][:100]}...\")\n",
    "\n",
    "# Clean criteria_texts before using it\n",
    "print(\"=== CLEANING DATA ===\")\n",
    "original_count = len(criteria_texts)\n",
    "\n",
    "# Filter out non-string and empty items\n",
    "clean_criteria_texts = []\n",
    "clean_criteria_details = []\n",
    "\n",
    "for i, text in enumerate(criteria_texts):\n",
    "    # Ensure it's a string and not empty\n",
    "    if isinstance(text, str) and text.strip():\n",
    "        clean_criteria_texts.append(text.strip())\n",
    "        if i < len(criteria_details):\n",
    "            clean_criteria_details.append(criteria_details[i])\n",
    "    else:\n",
    "        print(f\"Removing invalid item at index {i}: {type(text)} -> {repr(text)}\")\n",
    "\n",
    "# Update the lists\n",
    "criteria_texts = clean_criteria_texts\n",
    "criteria_details = clean_criteria_details\n",
    "\n",
    "print(f\"Cleaned data: {original_count} -> {len(criteria_texts)} items\")\n",
    "\n",
    "# Verify the cleaning worked\n",
    "if criteria_texts:\n",
    "    print(f\"All items are strings: {all(isinstance(x, str) for x in criteria_texts)}\")\n",
    "    print(f\"No empty strings: {all(len(x.strip()) > 0 for x in criteria_texts)}\")\n",
    "    print(f\"Sample: {criteria_texts[0][:50]}...\")\n",
    "else:\n",
    "    print(\"❌ ERROR: No valid criteria found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d630217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSM-5 Retriever\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class CriteriaRetriever:\n",
    "    def __init__(self, criteria: List[str]):\n",
    "        self.vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "        self.matrix = self.vectorizer.fit_transform(criteria)\n",
    "        # Precompute norms for cosine similarity\n",
    "        self.doc_norms = np.linalg.norm(self.matrix, axis=1) + 1e-10\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5):\n",
    "        q_vec = self.vectorizer.transform([query.lower().strip()])\n",
    "        dot_products = self.matrix @ q_vec.T  # Simple matrix multiplication\n",
    "        similarities = dot_products / (self.doc_norms * q_vec.toarray().flatten() + 1e-10)\n",
    "        top_indices = np.argsort(similarities.toarray().ravel())[-top_k:][::-1]\n",
    "        return [(i, similarities[i, 0]) for i in top_indices if similarities[i, 0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3bf2127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscartsao/miniforge3/envs/llmhe/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load TAIDE  (Not finished)\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "class LocalLLM:\n",
    "    def __init__(self, model_name: str = \"taide/Llama-3.1-TAIDE-LX-8B-Chat\"):\n",
    "        self.model_name = model_name\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        self.dtype = torch.float16 if self.device == \"cuda\" else torch.bfloat16\n",
    "        self.max_length = 2048\n",
    "\n",
    "    def generate(self, prompt: str, max_new_tokens: int = 512, temperature: float = 0.7, top_p: float = 0.9) -> str:\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        input_length = inputs.input_ids.shape[1]\n",
    "        if input_length + max_new_tokens > self.max_length:\n",
    "            raise ValueError(f\"Input length {input_length} with max_new_tokens {max_new_tokens} exceeds model's max_length {self.max_length}.\")\n",
    "        \n",
    "        with torch.autocast(device_type=self.device, dtype=self.dtype):\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e124e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Prompt\n",
    "\n",
    "def build_baseline_prompt(question: str) -> str:\n",
    "    return f\"\"\"你是一個具有DSM-5診斷標準知識的助理，能夠根據病患的文字描述給出你看到能的症狀，透過推理過程驗證你的答案是正確的。\n",
    "Patient Description: {question}\n",
    "Reasoning Process:\n",
    "Answer:\"\"\"\n",
    "def build_rag_prompt(question: str, retrieved_criteria: List[Tuple[str, float]]) -> str:\n",
    "    criteria_text = \"\\n\".join([f\"- {text} (Score: {score:.4f})\" for text, score in retrieved_criteria])\n",
    "    return f\"\"\"你是一個具有DSM-5診斷標準知識的助理，能夠根據病患的文字描述以及提供的診斷標準給出你看到的症狀，透過推理過程驗證你的答案是正確的。\n",
    "Patient Description: {question}\n",
    "Criteria:\n",
    "{criteria_text}\n",
    "Reasoning Process:\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffbdd626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Baseline & RAG\n",
    "def run_baseline(llm: LocalLLM, question: str) -> str:\n",
    "    prompt = build_baseline_prompt(question)\n",
    "    return llm.generate(prompt)\n",
    "def run_rag(llm: LocalLLM, retriever: CriteriaRetriever, question: str, top_k: int = 50) -> str:\n",
    "    retrieved_indices = retriever.retrieve(question, top_k=top_k)\n",
    "    retrieved_criteria = [(criteria_texts[i], score) for i, score in retrieved_indices]\n",
    "    prompt = build_rag_prompt(question, retrieved_criteria)\n",
    "    return llm.generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb03dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "原文：\n",
      "\n",
      "原翻譯：\n",
      "\n",
      "我該如何避免再次崩潰？ 我今年過得很差， 曾經有過想自殺的念頭， 我的愛人離開了， 我在大學裡不及格， 身體上也被打， 也被性侵， 今天我爺爺過世了。 我覺得自己快撐不下去， 只能勉強地做些基本的事來求生存， 同時也要當別人的支柱。 我的情緒韌性已經被擊垮了。 我感覺「還好」但我以前就有過這種感覺， 結果我只是在騙自己， 反而使情況更糟。 有什麼建議可以幫我更好地管理和處理我的情緒， 或是更了解自己？\n",
      "\n",
      "修正後的翻譯：\n",
      "\n",
      "你該如何避免再次崩潰？ 我今年過得很差， 曾經有過想自殺的念頭， 我的愛人離開了， 我在大學裡不及格， 身體上也被打， 也被性侵， 今天我爺爺過世了。 我覺得自己快撐不下去， 只能勉強地做些基本的事來求生存， 同時也要當別人的支柱。 我的情緒韌性已經被擊垮了。 我感覺「還好」但我以前就有過這種感覺， 結果我只是在騙自己， 反而使情況更糟。 有什麼建議可以幫我更好地管理和處理我的情緒， 或是更了解自己？\n",
      "\n",
      "(原文保持不變，直接翻譯而出)\n"
     ]
    }
   ],
   "source": [
    "# Test output\n",
    "print(posts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d2ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.18s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "scipy.sparse does not support dtype object. The only supported types are: bool, int8, uint8, int16, uint16, int32, uint32, int64, uint64, longlong, ulonglong, float32, float64, longdouble, complex64, complex128, clongdouble.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m LocalLLM()\n\u001b[0;32m----> 2\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mCriteriaRetriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcriteria_texts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mCriteriaRetriever.__init__\u001b[0;34m(self, criteria)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mfit_transform(criteria)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Precompute norms for cosine similarity\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_norms \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/llmhe/lib/python3.13/site-packages/numpy/linalg/_linalg.py:2827\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m add\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mabs\u001b[39m(x), axis\u001b[38;5;241m=\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims)\n\u001b[1;32m   2825\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   2826\u001b[0m     \u001b[38;5;66;03m# special case for speedup\u001b[39;00m\n\u001b[0;32m-> 2827\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m)\u001b[38;5;241m.\u001b[39mreal\n\u001b[1;32m   2828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sqrt(add\u001b[38;5;241m.\u001b[39mreduce(s, axis\u001b[38;5;241m=\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims))\n\u001b[1;32m   2829\u001b[0m \u001b[38;5;66;03m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[39;00m\n\u001b[1;32m   2830\u001b[0m \u001b[38;5;66;03m# are valid for vectors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/llmhe/lib/python3.13/site-packages/scipy/sparse/_matrix.py:45\u001b[0m, in \u001b[0;36mspmatrix.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/llmhe/lib/python3.13/site-packages/scipy/sparse/_base.py:804\u001b[0m, in \u001b[0;36m_spbase._matmul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_matmul_multivector(other)\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[0;32m--> 804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m err_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatmul: dimension mismatch with signature\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(other):\n",
      "File \u001b[0;32m~/miniforge3/envs/llmhe/lib/python3.13/site-packages/scipy/sparse/_data.py:135\u001b[0m, in \u001b[0;36m_data_matrix._mul_scalar\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_mul_scalar\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/llmhe/lib/python3.13/site-packages/scipy/sparse/_compressed.py:1172\u001b[0m, in \u001b[0;36m_cs_matrix._with_data\u001b[0;34m(self, data, copy)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a matrix with the same sparsity structure as self,\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;124;03mbut with different data.  By default the structure arrays\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;124;03m(i.e. .indptr and .indices) are copied.\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m-> 1172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m((data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr),\n\u001b[1;32m   1178\u001b[0m                           shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniforge3/envs/llmhe/lib/python3.13/site-packages/scipy/sparse/_compressed.py:113\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy, maxprint)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m check_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((M, N)), allow_nd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_nd)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     newdtype \u001b[38;5;241m=\u001b[39m \u001b[43mgetdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(newdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_format(full_check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/llmhe/lib/python3.13/site-packages/scipy/sparse/_sputils.py:137\u001b[0m, in \u001b[0;36mgetdtype\u001b[0;34m(dtype, a, default)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newdtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_dtypes:\n\u001b[1;32m    136\u001b[0m     supported_dtypes_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m supported_dtypes)\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscipy.sparse does not support dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe only supported types are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_dtypes_fmt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m newdtype\n",
      "\u001b[0;31mValueError\u001b[0m: scipy.sparse does not support dtype object. The only supported types are: bool, int8, uint8, int16, uint16, int32, uint32, int64, uint64, longlong, ulonglong, float32, float64, longdouble, complex64, complex128, clongdouble."
     ]
    }
   ],
   "source": [
    "model = LocalLLM()\n",
    "retriever = CriteriaRetriever(criteria_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test baseline prompt\n",
    "baseline_prompt = build_baseline_prompt(posts[0])\n",
    "rag_prompt = build_rag_prompt(model, retriever, posts[0])\n",
    "print(baseline_prompt)\n",
    "print(rag_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Evaluation Metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmhe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
